# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2014-2018, The Alibaba Group Holding Ltd.
# This file is distributed under the same license as the mars package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: mars \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-03-12 12:16+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.5.3\n"

#: ../../source/tensor/generated/mars.tensor.linalg.svd.rst:2
msgid "mars.tensor.linalg.svd"
msgstr ""

#~ msgid "Singular Value Decomposition."
#~ msgstr ""

#~ msgid ""
#~ "When `a` is a 2D tensor, it "
#~ "is factorized as ``u @ np.diag(s) "
#~ "@ vh = (u * s) @ vh``, "
#~ "where `u` and `vh` are 2D unitary"
#~ " tensors and `s` is a 1D tensor"
#~ " of `a`'s singular values. When `a`"
#~ " is higher-dimensional, SVD is "
#~ "applied in stacked mode as explained "
#~ "below."
#~ msgstr ""

#~ msgid "a"
#~ msgstr ""

#~ msgid "(..., M, N) array_like"
#~ msgstr ""

#~ msgid "A real or complex tensor with ``a.ndim >= 2``."
#~ msgstr ""

#~ msgid "method: {'tsqr'}, optional"
#~ msgstr ""

#~ msgid "method to calculate qr factorization, tsqr as default"
#~ msgstr ""

#~ msgid "TSQR is presented in:"
#~ msgstr ""

#~ msgid ""
#~ "A. Benson, D. Gleich, and J. "
#~ "Demmel. Direct QR factorizations for "
#~ "tall-and-skinny matrices in MapReduce "
#~ "architectures. IEEE International Conference "
#~ "on Big Data, 2013. "
#~ "http://arxiv.org/abs/1301.1071"
#~ msgstr ""

#~ msgid "u"
#~ msgstr ""

#~ msgid "{ (..., M, M), (..., M, K) } tensor"
#~ msgstr ""

#~ msgid ""
#~ "Unitary tensor(s). The first ``a.ndim -"
#~ " 2`` dimensions have the same size"
#~ " as those of the input `a`. The"
#~ " size of the last two dimensions "
#~ "depends on the value of `full_matrices`."
#~ " Only returned when `compute_uv` is "
#~ "True."
#~ msgstr ""

#~ msgid "s"
#~ msgstr ""

#~ msgid "(..., K) tensor"
#~ msgstr ""

#~ msgid ""
#~ "Vector(s) with the singular values, "
#~ "within each vector sorted in descending"
#~ " order. The first ``a.ndim - 2`` "
#~ "dimensions have the same size as "
#~ "those of the input `a`."
#~ msgstr ""

#~ msgid "vh"
#~ msgstr ""

#~ msgid "{ (..., N, N), (..., K, N) } tensor"
#~ msgstr ""

#~ msgid "LinAlgError"
#~ msgstr ""

#~ msgid "If SVD computation does not converge."
#~ msgstr ""

#~ msgid ""
#~ "SVD is usually described for the "
#~ "factorization of a 2D matrix :math:`A`."
#~ " The higher-dimensional case will be"
#~ " discussed below. In the 2D case, "
#~ "SVD is written as :math:`A = U "
#~ "S V^H`, where :math:`A = a`, "
#~ ":math:`U= u`, :math:`S= \\mathtt{np.diag}(s)` "
#~ "and :math:`V^H = vh`. The 1D "
#~ "tensor `s` contains the singular values"
#~ " of `a` and `u` and `vh` are"
#~ " unitary. The rows of `vh` are "
#~ "the eigenvectors of :math:`A^H A` and"
#~ " the columns of `u` are the "
#~ "eigenvectors of :math:`A A^H`. In both"
#~ " cases the corresponding (possibly non-"
#~ "zero) eigenvalues are given by ``s**2``."
#~ msgstr ""

#~ msgid ""
#~ "If `a` has more than two "
#~ "dimensions, then broadcasting rules apply, "
#~ "as explained in :ref:`routines.linalg-"
#~ "broadcasting`. This means that SVD is"
#~ " working in \"stacked\" mode: it "
#~ "iterates over all indices of the "
#~ "first ``a.ndim - 2`` dimensions and "
#~ "for each combination SVD is applied "
#~ "to the last two indices. The "
#~ "matrix `a` can be reconstructed from "
#~ "the decomposition with either ``(u * "
#~ "s[..., None, :]) @ vh`` or ``u "
#~ "@ (s[..., None] * vh)``. (The "
#~ "``@`` operator can be replaced by "
#~ "the function ``mt.matmul`` for python "
#~ "versions below 3.5.)"
#~ msgstr ""

#~ msgid "Reconstruction based on reduced SVD, 2D case:"
#~ msgstr ""

