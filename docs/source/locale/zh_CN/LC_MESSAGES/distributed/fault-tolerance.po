# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2014-2018, The Alibaba Group Holding Ltd.
# This file is distributed under the same license as the mars package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: mars \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-02-19 13:49+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../source/distributed/fault-tolerance.rst:2
msgid "Fault Tolerance"
msgstr "容错"

#: ../../source/distributed/fault-tolerance.rst:4
msgid ""
"Currently Mars supports two levels of fault tolerance: process-level and "
"worker-level. Scheduler-level support is not implemented now."
msgstr ""
"当下，Mars 在两个层面上有容错支持：进程级别容错和 Worker 级别容错，尚未"
"实现 Scheduler 级别容错"

#: ../../source/distributed/fault-tolerance.rst:8
msgid "Process-level Fault Tolerance"
msgstr "进程级别容错"

#: ../../source/distributed/fault-tolerance.rst:9
msgid ""
"Mars uses multiple processes in its worker. When a worker process fails, "
"for instance, gets killed because of out of memory, and the process is "
"not Process 0 where control actors run, Mars worker will mark relevant "
"tasks as failed, start another process, restore actors on it and the "
"retry mechanism will restart the failed task."
msgstr ""
"Mars Worker 在执行时为多进程。当一个进程因内存溢出等原因终止，且该进程"
"不是控制 Actor 所在的 0 号进程，Mars 将会把所有该进程上执行的 Operand "
"标记为失败，启动另一个进程，并在其上恢复之前进程上的所有 Actor 并重启失败"
"的 Operand。"

#: ../../source/distributed/fault-tolerance.rst:16
msgid "Worker-level Fault Tolerance"
msgstr "Worker 容错"

#: ../../source/distributed/fault-tolerance.rst:20
msgid "New in version 0.2.0a3"
msgstr ""

#: ../../source/distributed/fault-tolerance.rst:22
msgid ""
"As Mars uses execution graphs to schedule tasks, when some workers fail, "
"scheduler will find lost chunks and work out affected operands. After "
"that the spotted operands are rescheduled."
msgstr ""
"因为 Mars 使用执行图来调度 Operand，当一部分 Worker 不再相应时，Scheduler"
" 将会找出丢失的 Chunk，进而找到受影响的 Operand。此后，这部分 Operand 将"
"被重新调度。"

#: ../../source/distributed/fault-tolerance.rst:27
msgid "Failure Notification and Processing"
msgstr "故障消息传递和处理"

#: ../../source/distributed/fault-tolerance.rst:28
msgid ""
"When a worker fails to respond, actors both in other workers and "
"schedulers will detect it and send a feedback to ResourceActor, where "
"changes in worker list is accepted and broadcast into all the sessions. "
"When SessionActors accept the message, they will collect keys of missing "
"data and relay all collected information to running GraphActors, where "
"fail-over decisions are actually made."
msgstr ""
"当一个 Worker 停止响应，其他 Worker 及 Scheduler 中的各个 Actor 将感知"
"这一变化并将之回馈给 ResourceActor，此后 ResourceActor 将会把 Worker 列表"
"中的改变广播到所有 Session 中。SessionActor 在收到这些消息后，将会收集"
"当前 Session 中丢失的数据所对应的 key，并将收集到的所有信息转发给各个正在"
"运行的 GraphActor，并在 GraphActor 中执行真正的故障恢复操作。"

#: ../../source/distributed/fault-tolerance.rst:35
msgid "The failure notification procedure is illustrated in the graph below."
msgstr "整个故障通知流程如下图。"

#: ../../source/distributed/fault-tolerance.rst:39
msgid ""
"When accepting a fail-over call, a GraphActor will first try reassigning "
"states of affected operands, reassigning initial workers for initial "
"operands, and then send updates to corresponding OperandActors to rerun "
"these operands."
msgstr ""
"当收到故障恢复调用时，GraphActor 将首先尝试重新分配受故障影响 Operand 的"
"状态并重新分配初始节点的 Worker，此后向相关的 OperandActor 发送恢复请求。"

#: ../../source/distributed/fault-tolerance.rst:44
msgid "Reassigning States"
msgstr "状态重置"

#: ../../source/distributed/fault-tolerance.rst:45
msgid ""
"When some workers fail, data stored in these workers are lost. Therefore "
"we need to change the states of these operands in order to run them "
"again. As is stated in :ref:`operand states <operand_states>`, data "
"generated by an operand only exist when operands are in ``FINISHED`` "
"state, we perform a two-pass scanning procedure to calculate new "
"assignments for operands:"
msgstr ""
"当某些 Worker 失去联系，在这些 Worker 中存储的数据即告丢失。因而，我们"
"需要改变相关 Operand 的状态，以使它们能重新运行。由于存在 Operand 相关"
"数据的充要条件是 Operand 状态为 FINISHED，正如 :ref:`Operand 状态 <"
"operand_states>` 一节所说的那样，我们设计了一个两阶段的扫描过程来计算受"
"影响 Operand 的目标状态。"

#: ../../source/distributed/fault-tolerance.rst:51
msgid ""
"Scan all FINISHED operands whose data are lost and mark them and their "
"successors as affected;"
msgstr ""
"扫描所有状态为 FINISHED 且所带数据丢失的 Operand，将它们及它们的后继节点"
"标记为受影响；"

#: ../../source/distributed/fault-tolerance.rst:53
msgid "Scan the graph from bottom to top, starting from affected operands;"
msgstr "从受影响的 Operand 开始。从底部向上扫描 Graph；"

#: ../../source/distributed/fault-tolerance.rst:54
msgid ""
"For every affected operand, we scan its predecessors. If the data of the "
"predecessor is lost or in a state without data or generating data, for "
"instance, ``FREED`` or ``UNSCHEDULED``, the predecessor will be marked as"
" affected;"
msgstr ""
"扫描每个受影响 Operand 的前驱。如果前驱的数据丢失，或处于一个不持有数据的"
"状态中（例如 ``FREED`` 或者 ``UNSCHEDULED``），前驱将被标记为受影响；"

#: ../../source/distributed/fault-tolerance.rst:58
msgid ""
"Mark current operand as ``READY`` when no predecessors are affected, "
"otherwise it will be marked as ``UNSCHEDULED``;"
msgstr ""
"如果当前节点没有前驱受影响，则将该节点的新状态指定为 ``READY``，否则指定"
"为 ``UNSCHEDULED``；"

#: ../../source/distributed/fault-tolerance.rst:60
msgid ""
"When there are no affected operands to be scanned, stop, otherwise go to "
"Step 2."
msgstr "当所有受影响 Operand 均已处理完成，则停止，否则继续前往步骤 2。"

#: ../../source/distributed/fault-tolerance.rst:64
msgid "Reassigning Initial Workers"
msgstr "重新分配初始 Worker"

#: ../../source/distributed/fault-tolerance.rst:65
msgid ""
"When workers fail, some of initial operands assigned in :ref:`graph "
"preparation <graph_preparation>` step may not have workers to execute on."
" What's more, change in number of workers may lead to imbalance in worker"
" assignments. We solve this problem by applying an adaptive worker "
"reassigning strategy. The algorithm framework is similar with the "
"original one except that we do not visit initial operands which are "
"executed, and the stop criterion of visiting operands in Step 3 is now "
"limited to the average number of operands per worker minus the number of "
"operands already executed or determined to run in the candidate worker."
msgstr ""
"当一部分 Worker 失去联系，一些在 :ref:`Graph 初始化 <graph_preparation>` "
"时被指派 Worker 的初始节点可能失去指派的 Worker。与此同时，Worker 数量的"
"变化也会导致 Worker 分配的不平衡。我们使用一种自适应的 Worker 重分配算法"
"来解决这一问题。该算法框架与最初的初始节点分配算法一致，区别在于我们并不"
"访问已经被执行过的初始节点，同时原算法步骤 3 中停止条件所涉及的访问节点"
"范围限制为平均到每个 Worker 的节点数减去已经在该 Worker 中执行过的节点数"
"。"

